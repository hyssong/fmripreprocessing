{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bcd2cb1",
   "metadata": {},
   "source": [
    "# Preprocessing after fMRIprep (using AFNI & FSL)\n",
    "\n",
    "Code created: August 22, 2023, Hayoung Song (hyssong@uchicago.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# dependencies: AFNI & FSL (fMRI processing softwares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114aa07",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname_fmriprep   = './fmriprepoutput'\n",
    "dirname_preprocess = './preprocess'\n",
    "if os.path.exists(dirname_preprocess)==0:\n",
    "    os.mkdir(dirname_preprocess)\n",
    "\n",
    "TR = 1.5\n",
    "\n",
    "# get subject list in fMRIprep output folder\n",
    "flist = [i for i in np.sort(os.listdir(dirname_fmriprep)) if i.startswith('sub-')]\n",
    "tasklist = ['PreExposure_run-01','PreTest_run-01','Repeated_run-01','Repeated_run-02','Repeated_run-03',\n",
    "            'Repeated_run-04','Repeated_run-05','Repeated_run-06','PostExposure_run-01','PostTest_run-01']\n",
    "print(flist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af9b10",
   "metadata": {},
   "source": [
    "## Quality check: Head motion\n",
    "This section loops over all participants' all task runs to check for head motion.\n",
    "This is used as a quality check; no files are processed/generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec928b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_thres = 0.5\n",
    "for si, subname in enumerate(flist):\n",
    "    print(subname)\n",
    "    \n",
    "    for ti, task in enumerate(tasklist):\n",
    "        t = pd.read_csv(dirname_fmriprep+'/'+subname+'/'+'/func/'+subname+'_task-'+task+'_desc-confounds_timeseries.tsv',\n",
    "                        delimiter='\\t')\n",
    "        \n",
    "        # time course of framewise displacement (FD)\n",
    "        fd = t['framewise_displacement']\n",
    "        \n",
    "        # proportion of frames where FD >= fd_thres\n",
    "        outliers = np.sum(fd >= fd_thres) / (len(fd)-np.sum(pd.isna(fd)))\n",
    "        \n",
    "        print('   meanFD: '+str(np.round(np.nanmean(fd),2))+', %FD>='+str(fd_thres)+': '+str(np.round(outliers*100, 2))+'% ['+task+']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe56ac",
   "metadata": {},
   "source": [
    "## Creating outlier & confound matrices\n",
    "This section creates \"preprocess\" folder for each participant/run and save outlier vector and confound regressor matrix as .1D files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which variables to regress out? column names of *_desc-confounds_timeseries.tsv\n",
    "variables=['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z',\n",
    "           'trans_x_derivative1', 'trans_y_derivative1', 'trans_z_derivative1',\n",
    "           'rot_x_derivative1', 'rot_y_derivative1', 'rot_z_derivative1',\n",
    "           'trans_x_derivative1_power2', 'trans_y_derivative1_power2',\n",
    "           'trans_z_derivative1_power2', 'rot_x_derivative1_power2',\n",
    "           'rot_y_derivative1_power2', 'rot_z_derivative1_power2',\n",
    "           'trans_x_power2', 'trans_y_power2', 'trans_z_power2', 'rot_x_power2',\n",
    "           'rot_y_power2', 'rot_z_power2', 'global_signal', 'csf', 'white_matter']\n",
    "# 24 motion parameters, global signal, CSF, white matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6de7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for si, subname in enumerate(flist):\n",
    "    print(subname)\n",
    "    if os.path.exists(dirname_preprocess+'/'+subname)==0:\n",
    "        os.mkdir(dirname_preprocess+'/'+subname)\n",
    "    \n",
    "    for ti, task in enumerate(tasklist):\n",
    "        t = pd.read_csv(dirname_fmriprep+'/'+subname+'/'+'/func/'+subname+'_task-'+task+'_desc-confounds_timeseries.tsv',\n",
    "                        delimiter='\\t')\n",
    "        \n",
    "        # ------ outliers ------ #\n",
    "        # head motion outliers (FD, DVARS) & non-steady-state outliers\n",
    "        # default fMRIprep outlier detection: exceeding 0.5 mm FD or 1.5 standardized DVARS\n",
    "        outlier_columns = [i for i in t.columns if i.startswith('motion_outlier') or i.startswith('non_steady_state_outlier')]\n",
    "        \n",
    "        # time points to be included (1), to be excluded (0)\n",
    "        outliers = np.zeros((len(t),))+np.nan\n",
    "        outliers[np.where(np.sum(np.array(t[outlier_columns]),1)>0)[0]] = 0\n",
    "        outliers[np.where(np.sum(np.array(t[outlier_columns]),1)==0)[0]] = 1\n",
    "        \n",
    "        # save outliers file\n",
    "        if os.path.exists(dirname_preprocess+'/'+subname+'/task-'+task)==0:\n",
    "            os.mkdir(dirname_preprocess+'/'+subname+'/task-'+task)\n",
    "        pd.DataFrame(outliers).to_csv(dirname_preprocess+'/'+subname+'/task-'+task+'/'+subname+'_task-'+task+'_outliers.1D', \n",
    "                                      index=False, header=False)\n",
    "        \n",
    "        # ------ regressors ------ #\n",
    "        # dupliace values in second row if the first row is NaN\n",
    "        for varb in variables:\n",
    "            if pd.isna(t[varb][0]):\n",
    "                t[varb][0] = t[varb][1]\n",
    "        regressors = t[variables]\n",
    "        \n",
    "        # save regressors file\n",
    "        regressors.to_csv(dirname_preprocess+'/'+subname+'/task-'+task+'/'+subname+'_task-'+task+'_confounds_regressors.1D', \n",
    "                          index=False, header=False)\n",
    "        regressors.to_csv(dirname_preprocess+'/'+subname+'/task-'+task+'/'+subname+'_task-'+task+'_confounds_regressors.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a805f",
   "metadata": {},
   "source": [
    "## Run preprocessing\n",
    "This section runs additional preprocessing on the fMRIprep outputs. Dependencies: AFNI & FSL. <br>\n",
    "\n",
    "1. Apply brain mask to the preprocessed EPI\n",
    "2. Intensity normalization\n",
    "3. Regressing out nuissance variables: 24 motion parameters, WM, CSF, global signal, low-frequency signals, linear trend\n",
    "4. Spatial smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "FWHM = 5 # smoothing factor: if voxel size = 2mm, usually fwhm = 4, if voxel size = 3mm, usually fwhm = 5-6\n",
    "\n",
    "for si, subname in enumerate(flist):\n",
    "    for ti, task in enumerate(tasklist):\n",
    "        print(subname+' '+task)\n",
    "        \n",
    "        # ------ setup ------ #\n",
    "        # fmriprep directory\n",
    "        prep_dir = dirname_fmriprep+'/'+subname+'/func/'\n",
    "        # preprocessed output directory\n",
    "        proc_dir = dirname_preprocess+'/'+subname+'/task-'+task\n",
    "        \n",
    "        # preprocessed, MNI-registered EPI\n",
    "        prep_img = prep_dir+subname+'_task-'+task+'_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "        # brain mask\n",
    "        prep_mask_img = prep_dir+subname+'_task-'+task+'_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz'\n",
    "        \n",
    "        # ------------ #\n",
    "        print('1. Mask fMRIprep output')\n",
    "        os.system('3dcalc -a '+prep_img+' -b '+prep_mask_img+' -expr \"(a*b)\" -prefix '+proc_dir+'/1_'+subname+'_task-'+task+'_fmriprep_output.nii.gz')\n",
    "        \n",
    "        # ------------ #\n",
    "        print('2. Intensity normalization')\n",
    "        os.system('fslmaths '+proc_dir+'/1_'+subname+'_task-'+task+'_fmriprep_output.nii.gz -inm 10000 '+proc_dir+'/2_'+subname+'_task-'+task+'_intensity_normalization.nii.gz')\n",
    "        \n",
    "        # ------------ #\n",
    "        print('3. Create low-frequency signal regressors for high-pass filtering')\n",
    "        # 128 s cutoff\n",
    "        os.system('1dBport -input '+proc_dir+'/2_'+subname+'_task-'+task+'_intensity_normalization.nii.gz -TR '+\n",
    "                 str(TR)+' -band 0 0.0078 -nozero > '+proc_dir+'/tmp_rm.hpass.1D')\n",
    "        os.system('1d_tool.py -infile '+proc_dir+'/tmp_rm.hpass.1D -write '+proc_dir+'/'+subname+'_task-'+task+'_highpass_regressors.1D')\n",
    "        os.system('rm '+proc_dir+'/tmp_rm.hpass.1D')\n",
    "        \n",
    "        # ------------ #\n",
    "        print('4. Create regressors')\n",
    "        # creating *_xmat.1D matrix that combines low-frequency signals, linear trend, fMRIprep output confound matrix, and an intercept\n",
    "        os.system('3dDeconvolve -input '+proc_dir+'/2_'+subname+'_task-'+task+'_intensity_normalization.nii.gz '+\n",
    "                  '-ortvec '+proc_dir+'/'+subname+'_task-'+task+'_highpass_regressors.1D highpass '+\n",
    "                  '-ortvec '+proc_dir+'/'+subname+'_task-'+task+'_confounds_regressors.1D confounds '+\n",
    "                  '-polort 1 '+\n",
    "                  '-fout -tout -x1D '+proc_dir+'/'+subname+'_task-'+task+'_xmat.1D '+\n",
    "                  '-fitts fitts -errts errts -x1D_stop -bucket stats')\n",
    "        \n",
    "        # ------------ #\n",
    "        print('5. Regressing out nuissance variables')\n",
    "        # inputs\n",
    "        #    regressors: *_xmat.1D\n",
    "        #    censor frames: *_outliers.1D (1: included frames, 0: excluded frames)\n",
    "        #    (censored frames are treated as ZEROS: this should be converted to NaNs during analyses)\n",
    "        # outputs\n",
    "        #    3_*_nuissance_regressed.nii.gz\n",
    "        os.system('3dTproject -polort 0 -input '+proc_dir+'/2_'+subname+'_task-'+task+'_intensity_normalization.nii.gz '+\n",
    "                  '-ort '+proc_dir+'/'+subname+'_task-'+task+'_xmat.1D '+\n",
    "                  '-censor '+proc_dir+'/'+subname+'_task-'+task+'_outliers.1D '+\n",
    "                  '-cenmode ZERO '+\n",
    "                  '-prefix '+proc_dir+'/3_'+subname+'_task-'+task+'_nuissance_regressed.nii.gz')\n",
    "        \n",
    "        # ------------ #\n",
    "        print('6. Spatial smoothing with FWHM = '+str(FWHM))\n",
    "        os.system('3dmerge -quiet -1blur_fwhm '+str(FWHM)+' -doall -prefix '+proc_dir+'/4_'+subname+'_task-'+task+'_smoothed.nii.gz '+\n",
    "                 proc_dir+'/3_'+subname+'_task-'+task+'_nuissance_regressed.nii.gz')\n",
    "        print('')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
